var documenterSearchIndex = {"docs":
[{"location":"gettingstarted/#Computing-Approximate-Likelihoods-with-Probabilistic-Numerics-and-Fenrir.jl","page":"Fenrr.jl in a nutshell","title":"Computing Approximate Likelihoods with Probabilistic Numerics and Fenrir.jl","text":"","category":"section"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"using LinearAlgebra\nusing OrdinaryDiffEq, ProbNumDiffEq, Plots\nusing Fenrir\nstack(x) = copy(reduce(hcat, x)') # convenient\nnothing # hide","category":"page"},{"location":"gettingstarted/#The-problem-statement-as-math","page":"Fenrr.jl in a nutshell","title":"The problem statement as math","text":"","category":"section"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"Let's assume we have an initial value problem (IVP)","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"beginaligned\ndoty = f_theta(y t) qquad y(t_0) = y_0\nendaligned","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"which we observe through a set mathcalD = u(t_n)_n=1^N of noisy data points","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"beginaligned\nu(t_n) = H y(t_n) + v_n qquad v_n sim mathcalN(0 R)\nendaligned","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"The question of interest is: How can we compute the marginal likelihood p(mathcalD mid theta)? Short answer: We can't. It's intractable, because exactly computing the true IVP solution y(t) is intractable. What we can do however is compute an approximate marginal likelihood. This is what Fenrir.jl provides. For details, check out the paper.","category":"page"},{"location":"gettingstarted/#The-setup,-in-code","page":"Fenrr.jl in a nutshell","title":"The setup, in code","text":"","category":"section"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"Let's assume that the true underlying dynamics are given by a FitzHugh-Nagumo model","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"function f(du, u, p, t)\n    a, b, c = p\n    du[1] = c*(u[1] - u[1]^3/3 + u[2])\n    du[2] = -(1/c)*(u[1] -  a - b*u[2])\nend\nu0 = [-1.0, 1.0]\ntspan = (0.0, 20.0)\np = (0.2, 0.2, 3.0)\ntrue_prob = ODEProblem(f, u0, tspan, p)","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"from which we generate some artificial noisy data","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"true_sol = solve(true_prob, Vern9(), abstol=1e-10, reltol=1e-10)\n\ntimes = 1:0.5:20\nobservation_noise_var = 1e-1\nodedata = [true_sol(t) .+ sqrt(observation_noise_var) * randn(length(u0)) for t in times]\n\nplot(true_sol, color=:black, linestyle=:dash, label=[\"True Solution\" \"\"])\nscatter!(times, stack(odedata), markersize=2, markerstrokewidth=0.1, color=1, label=[\"Noisy Data\" \"\"])","category":"page"},{"location":"gettingstarted/#Computing-the-negative-log-likelihood","page":"Fenrr.jl in a nutshell","title":"Computing the negative log-likelihood","text":"","category":"section"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"To evaluate the likelihood given a parameter estimate theta_textest, we just need to call fenrir_nll:","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"p_est = (0.1, 0.1, 2.0)\nprob = remake(true_prob, p=p_est)\ndata = (t=times, u=odedata)\nκ² = 1e10\nnll, _, _ = fenrir_nll(prob, data, observation_noise_var, κ²; dt=1e-1)\nnll","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"Voilà! This is the marginal negative log-likelihood!","category":"page"},{"location":"gettingstarted/","page":"Fenrr.jl in a nutshell","title":"Fenrr.jl in a nutshell","text":"You can use it as any other NLL: Optimize it to compute maximum-likelihood estimates or MAPs, or plug it into MCMC to sample from the posterior. In our paper we compute MLEs by pairing Fenrir with Optimization.jl and ForwardDiff.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Fenrir","category":"page"},{"location":"#Fenrir","page":"Home","title":"Fenrir","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Fenrir exports just a single function:","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"fenrir_nll","category":"page"},{"location":"#Fenrir.fenrir_nll","page":"Home","title":"Fenrir.fenrir_nll","text":"fenrir_nll(prob::ODEProblem, data::NamedTuple{(:t, :u)}, observation_noise_var::Real,\n    diffusion_var::Union{Real,Vector{<:Real}};\n    adaptive=false, dt=false,  proj=I, order=3::Int, tstops=[])\n\nCompute the \"Fenrir\" approximate negative log-likelihood (NLL) of the data.\n\nThis is a convenience function that\n\nSolves the ODE with a ProbNumDiffEq.EK1 of the specified order and with a diffusion as provided by the diffusion_var argument, and\nFits the ODE posterior to the data via Kalman filtering and thereby computes the negative log-likelihood on the way.\n\nBy default, the solver steps exactly through the time points data.t. In addition, you can provide a step size with dt or time stops with tstops. Or, set adaptive=true for adaptive step-size selection - use at your own risk!\n\nReturns a tuple (nll::Real, times::Vector{Real}, states::StructVector{Gaussian}), where states contains the filtering posterior. Its mean and covariance can be accessed with states.μ and states.Σ.\n\nArguments\n\nprob::ODEProblem: the initial value problem of interest\ndata::NamedTuple{{(:t, :u)}}: the data to be fitted\nobservation_noise_var::Real: the scalar observation noise variance\ndiffusion_var: the diffusion parameter for the integrated Wiener process prior; this plays a similar role as kernel hyperparamers in Gaussian-process regression\ndt=false: step size parameter, passed to OrdinaryDiffEq.init\nadaptive=false: flag to determine if adaptive step size selection should be used; use at your own risk!\ntstops=[]: additional time stops the algorithm should step through; passed to OrdinaryDiffEq.solve\norder::Int=3: the order of the ProbNumDiffEq.EK1 solver\nproj=I: the matrix which maps the ODE state to the measurements; typically a projection\n\n\n\n\n\n","category":"function"}]
}
